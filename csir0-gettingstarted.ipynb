{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:36.243414Z","iopub.execute_input":"2025-12-19T20:58:36.243719Z","iopub.status.idle":"2025-12-19T20:58:36.521772Z","shell.execute_reply.started":"2025-12-19T20:58:36.243694Z","shell.execute_reply":"2025-12-19T20:58:36.521196Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\n\nimport timm\nfrom torchvision import transforms\nfrom sklearn.model_selection import KFold\nfrom torch.cuda.amp import autocast, GradScaler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:36.522805Z","iopub.execute_input":"2025-12-19T20:58:36.523093Z","iopub.status.idle":"2025-12-19T20:58:47.204925Z","shell.execute_reply.started":"2025-12-19T20:58:36.523076Z","shell.execute_reply":"2025-12-19T20:58:47.204320Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Config:\n    train_path = \"/kaggle/input/csiro-biomass/train.csv\"\n    test_path = \"/kaggle/input/csiro-biomass/test\"\n    sample_sub = \"/kaggle/input/csiro-biomass/sample_submission.csv\"\n    root_dir = \"/kaggle/input/csiro-biomass\"\n    sample_id = \"ID1001187975__Dry_Clover_g\"\n    TARGET_NAMES = [\n        \"Dry_Green_g\",\n        \"Dry_Dead_g\",\n        \"Dry_Clover_g\",\n        \"GDM_g\",\n        \"Dry_Total_g\",\n    ]\n\n\nconfig = Config()\n\n\ndef weighted_r2_score(y_true, y_pred):\n        weights = np.array([0.1, 0.1, 0.1, 0.2, 0.5])\n        r2s = []\n    \n        for i in range(5):\n            yt, yp = y_true[:, i], y_pred[:, i]\n            ss_res = np.sum((yt - yp) ** 2)\n            ss_tot = np.sum((yt - yt.mean()) ** 2)\n            r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n            r2s.append(r2)\n    \n        r2s = np.array(r2s)\n        return np.sum(r2s * weights) / weights.sum(), r2s\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.205548Z","iopub.execute_input":"2025-12-19T20:58:47.205881Z","iopub.status.idle":"2025-12-19T20:58:47.211636Z","shell.execute_reply.started":"2025-12-19T20:58:47.205865Z","shell.execute_reply":"2025-12-19T20:58:47.210812Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = pd.read_csv(config.train_path)\n\ntrain_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.213350Z","iopub.execute_input":"2025-12-19T20:58:47.213585Z","iopub.status.idle":"2025-12-19T20:58:47.266597Z","shell.execute_reply.started":"2025-12-19T20:58:47.213569Z","shell.execute_reply":"2025-12-19T20:58:47.266017Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                    sample_id              image_path Sampling_Date State  \\\n0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n3   ID1011485656__Dry_Total_g  train/ID1011485656.jpg      2015/9/4   Tas   \n4         ID1011485656__GDM_g  train/ID1011485656.jpg      2015/9/4   Tas   \n\n           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n3  Ryegrass_Clover           0.62         4.6667   Dry_Total_g  48.2735  \n4  Ryegrass_Clover           0.62         4.6667         GDM_g  16.2750  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>image_path</th>\n      <th>Sampling_Date</th>\n      <th>State</th>\n      <th>Species</th>\n      <th>Pre_GSHH_NDVI</th>\n      <th>Height_Ave_cm</th>\n      <th>target_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID1011485656__Dry_Clover_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Clover_g</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID1011485656__Dry_Dead_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Dead_g</td>\n      <td>31.9984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID1011485656__Dry_Green_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Green_g</td>\n      <td>16.2751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID1011485656__Dry_Total_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Total_g</td>\n      <td>48.2735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID1011485656__GDM_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>GDM_g</td>\n      <td>16.2750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df = train_df.pivot(\n    index=\"image_path\",\n    columns=\"target_name\", \n    values=\"target\"\n).reset_index()\n\ndf.columns.name = None \n\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.267249Z","iopub.execute_input":"2025-12-19T20:58:47.267506Z","iopub.status.idle":"2025-12-19T20:58:47.296739Z","shell.execute_reply.started":"2025-12-19T20:58:47.267478Z","shell.execute_reply":"2025-12-19T20:58:47.296227Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"               image_path  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  Dry_Total_g  \\\n0  train/ID1011485656.jpg        0.0000     31.9984      16.2751      48.2735   \n1  train/ID1012260530.jpg        0.0000      0.0000       7.6000       7.6000   \n2  train/ID1025234388.jpg        6.0500      0.0000       0.0000       6.0500   \n3  train/ID1028611175.jpg        0.0000     30.9703      24.2376      55.2079   \n4  train/ID1035947949.jpg        0.4343     23.2239      10.5261      34.1844   \n\n     GDM_g  \n0  16.2750  \n1   7.6000  \n2   6.0500  \n3  24.2376  \n4  10.9605  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>Dry_Clover_g</th>\n      <th>Dry_Dead_g</th>\n      <th>Dry_Green_g</th>\n      <th>Dry_Total_g</th>\n      <th>GDM_g</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/ID1011485656.jpg</td>\n      <td>0.0000</td>\n      <td>31.9984</td>\n      <td>16.2751</td>\n      <td>48.2735</td>\n      <td>16.2750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/ID1012260530.jpg</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n      <td>7.6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/ID1025234388.jpg</td>\n      <td>6.0500</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>6.0500</td>\n      <td>6.0500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/ID1028611175.jpg</td>\n      <td>0.0000</td>\n      <td>30.9703</td>\n      <td>24.2376</td>\n      <td>55.2079</td>\n      <td>24.2376</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/ID1035947949.jpg</td>\n      <td>0.4343</td>\n      <td>23.2239</td>\n      <td>10.5261</td>\n      <td>34.1844</td>\n      <td>10.9605</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"class BiomassDataset(Dataset):\n    def __init__(self, df, root_dir, transform):\n        self.df = df.reset_index(drop=True)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(os.path.join(self.root_dir, row[\"image_path\"])).convert(\"RGB\")\n        img = self.transform(img)\n\n        target = torch.tensor([\n            row[\"Dry_Green_g\"],\n            row[\"Dry_Dead_g\"],\n            row[\"Dry_Clover_g\"],\n            row[\"GDM_g\"],\n            row[\"Dry_Total_g\"]\n        ], dtype=torch.float32)\n\n        return img, target\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.297368Z","iopub.execute_input":"2025-12-19T20:58:47.297653Z","iopub.status.idle":"2025-12-19T20:58:47.302597Z","shell.execute_reply.started":"2025-12-19T20:58:47.297636Z","shell.execute_reply":"2025-12-19T20:58:47.301957Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nval_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.303251Z","iopub.execute_input":"2025-12-19T20:58:47.303482Z","iopub.status.idle":"2025-12-19T20:58:47.316552Z","shell.execute_reply.started":"2025-12-19T20:58:47.303466Z","shell.execute_reply":"2025-12-19T20:58:47.315901Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ConvNeXtRegressor(nn.Module):\n    def __init__(self, num_targets=5):\n        super().__init__()\n\n        self.backbone = timm.create_model(\n            \"convnext_tiny\",\n            pretrained=True,\n            features_only=False\n        )\n        self.backbone.head = nn.Identity()\n\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.head = nn.Linear(768, num_targets)\n\n    def forward(self, x):\n        x = self.backbone.forward_features(x)\n        x = self.pool(x).flatten(1)\n        return self.head(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.317250Z","iopub.execute_input":"2025-12-19T20:58:47.317570Z","iopub.status.idle":"2025-12-19T20:58:47.335918Z","shell.execute_reply.started":"2025-12-19T20:58:47.317551Z","shell.execute_reply":"2025-12-19T20:58:47.335051Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, scaler, device):\n    model.train()\n    total_loss = 0\n\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        with autocast():\n            preds = model(x)\n            loss = criterion(preds, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item() * x.size(0)\n\n    return total_loss / len(loader.dataset)\n\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    preds, trues = [], []\n\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            p = model(x)\n\n            total_loss += criterion(p, y).item() * x.size(0)\n            preds.append(p.cpu())\n            trues.append(y.cpu())\n\n    preds = torch.cat(preds).numpy()\n    trues = torch.cat(trues).numpy()\n\n    wr2, _ = weighted_r2_score(trues, preds)\n    return total_loss / len(loader.dataset), wr2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.336649Z","iopub.execute_input":"2025-12-19T20:58:47.336900Z","iopub.status.idle":"2025-12-19T20:58:47.349952Z","shell.execute_reply.started":"2025-12-19T20:58:47.336879Z","shell.execute_reply":"2025-12-19T20:58:47.349403Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(df)):\n    print(f\"\\n===== Fold {fold+1} =====\")\n\n    train_ds = BiomassDataset(df.iloc[tr_idx], config.root_dir, train_tfms)\n    val_ds   = BiomassDataset(df.iloc[va_idx], config.root_dir, val_tfms)\n\n    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2)\n    val_loader   = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=2)\n\n    model = ConvNeXtRegressor().to(device)\n    criterion = nn.SmoothL1Loss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n    scaler = GradScaler()\n\n    best_r2 = -1\n\n    for epoch in range(10):\n        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler, device)\n        val_loss, val_r2 = validate(model, val_loader, criterion, device)\n        scheduler.step()\n\n        print(f\"Epoch {epoch+1}: Train {train_loss:.4f} | Val {val_loss:.4f} | R2 {val_r2:.4f}\")\n\n        if val_r2 > best_r2:\n            best_r2 = val_r2\n            torch.save(model.state_dict(), f\"best_convnext_fold{fold}.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T20:58:47.351596Z","iopub.execute_input":"2025-12-19T20:58:47.351922Z","iopub.status.idle":"2025-12-19T21:22:30.222884Z","shell.execute_reply.started":"2025-12-19T20:58:47.351905Z","shell.execute_reply":"2025-12-19T21:22:30.221953Z"}},"outputs":[{"name":"stdout","text":"\n===== Fold 0 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036c3013056a46f48d58ee339cf5000d"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: Train 17.2206 | Val 12.9463 | R2 -0.1123\nEpoch 2: Train 12.9558 | Val 12.0118 | R2 0.1102\nEpoch 3: Train 11.9523 | Val 11.0985 | R2 0.2639\nEpoch 4: Train 11.1660 | Val 9.1224 | R2 0.3509\nEpoch 5: Train 10.0590 | Val 9.1019 | R2 0.4341\nEpoch 6: Train 9.8837 | Val 8.0522 | R2 0.5106\nEpoch 7: Train 8.4177 | Val 9.1471 | R2 0.4863\nEpoch 8: Train 7.4780 | Val 7.8158 | R2 0.5249\nEpoch 9: Train 6.8556 | Val 7.6056 | R2 0.5828\nEpoch 10: Train 6.4479 | Val 7.1627 | R2 0.5995\n\n===== Fold 1 =====\nEpoch 1: Train 15.9379 | Val 14.2444 | R2 0.0357\nEpoch 2: Train 12.0668 | Val 14.1694 | R2 0.1175\nEpoch 3: Train 11.3486 | Val 13.6263 | R2 -0.0294\nEpoch 4: Train 10.2387 | Val 12.0870 | R2 0.1918\nEpoch 5: Train 9.3385 | Val 12.1167 | R2 0.3170\nEpoch 6: Train 8.4874 | Val 10.5415 | R2 0.3097\nEpoch 7: Train 7.9967 | Val 9.8787 | R2 0.3877\nEpoch 8: Train 6.9945 | Val 9.6385 | R2 0.4854\nEpoch 9: Train 6.5361 | Val 9.2224 | R2 0.4646\nEpoch 10: Train 6.1417 | Val 8.8870 | R2 0.5256\n\n===== Fold 2 =====\nEpoch 1: Train 16.2479 | Val 14.9931 | R2 -0.0856\nEpoch 2: Train 13.5129 | Val 14.3627 | R2 -0.0850\nEpoch 3: Train 12.6060 | Val 12.8074 | R2 0.0897\nEpoch 4: Train 12.5720 | Val 14.1430 | R2 -0.0553\nEpoch 5: Train 12.2665 | Val 11.9116 | R2 0.2234\nEpoch 6: Train 11.0573 | Val 11.0673 | R2 0.2639\nEpoch 7: Train 10.8686 | Val 11.0277 | R2 0.2838\nEpoch 8: Train 10.1055 | Val 10.1711 | R2 0.3614\nEpoch 9: Train 9.6589 | Val 9.7288 | R2 0.4182\nEpoch 10: Train 9.4231 | Val 9.6697 | R2 0.4255\n\n===== Fold 3 =====\nEpoch 1: Train 17.3562 | Val 13.6591 | R2 -0.0266\nEpoch 2: Train 13.0209 | Val 10.9367 | R2 0.2562\nEpoch 3: Train 12.0584 | Val 10.8339 | R2 0.2033\nEpoch 4: Train 10.9603 | Val 11.7794 | R2 0.1608\nEpoch 5: Train 10.2025 | Val 10.5708 | R2 0.3189\nEpoch 6: Train 9.9144 | Val 9.7006 | R2 0.3517\nEpoch 7: Train 8.6458 | Val 9.6248 | R2 0.3651\nEpoch 8: Train 8.2812 | Val 9.1011 | R2 0.4120\nEpoch 9: Train 7.5889 | Val 8.2165 | R2 0.5119\nEpoch 10: Train 7.2708 | Val 8.1636 | R2 0.5180\n\n===== Fold 4 =====\nEpoch 1: Train 16.5387 | Val 13.2351 | R2 0.0071\nEpoch 2: Train 12.4027 | Val 10.7857 | R2 0.1739\nEpoch 3: Train 11.3438 | Val 10.7126 | R2 0.2541\nEpoch 4: Train 10.4289 | Val 12.3580 | R2 0.0144\nEpoch 5: Train 9.5644 | Val 10.3934 | R2 0.2662\nEpoch 6: Train 8.3065 | Val 10.4696 | R2 0.4305\nEpoch 7: Train 7.9796 | Val 8.9455 | R2 0.4794\nEpoch 8: Train 7.3923 | Val 8.2373 | R2 0.5378\nEpoch 9: Train 6.3972 | Val 8.1801 | R2 0.5358\nEpoch 10: Train 5.8931 | Val 8.0370 | R2 0.5653\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}